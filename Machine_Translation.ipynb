{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import random"
      ],
      "metadata": {
        "id": "mfogjPnfUSZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample dataset (English to French)\n",
        "data = [\n",
        "    (\"hello\", \"bonjour\"),\n",
        "    (\"how are you\", \"comment ça va\"),\n",
        "    (\"I love you\", \"je t'aime\"),\n",
        "    (\"thank you\", \"merci\"),\n",
        "    (\"good morning\", \"bonjour\"),\n",
        "    (\"good night\", \"bonne nuit\"),\n",
        "    (\"see you later\", \"à plus tard\"),\n",
        "]\n",
        "\n",
        "# Prepare input and output pairs\n",
        "input_sentences, target_sentences = zip(*data)\n",
        "\n",
        "input_sentences, target_sentences"
      ],
      "metadata": {
        "id": "OHlVuNbXUSXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create vocab\n",
        "def build_vocab(data):\n",
        "  words = set(\" \".join(data).split())\n",
        "  word_to_idx = {word: idx for idx, word in enumerate(words)}\n",
        "  idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
        "\n",
        "  return word_to_idx, idx_to_word, len(words) + 1 # for padding\n",
        "\n",
        "\n",
        "\n",
        "# Prepare vocabularies\n",
        "input_vocab, input_idx_to_word, input_vocab_size = build_vocab(input_sentences)\n",
        "target_vocab, target_idx_to_word, target_vocab_size = build_vocab(target_sentences)\n",
        "# input_vocab['<SOS>'] = 0\n",
        "# target_vocab['<SOS>'] = 0\n",
        "# input_idx_to_word[0] = '<SOS>'\n",
        "# target_idx_to_word[0] = '<SOS>'\n",
        "\n",
        "\n",
        "# Encode sentences\n",
        "def encode_sentence(sentence, vocab):\n",
        "    return [vocab[word] for word in sentence.split()] + [0]  # Add padding (0)\n",
        "\n",
        "input_encoded = [encode_sentence(sentence, input_vocab) for sentence in input_sentences]\n",
        "target_encoded = [encode_sentence(sentence, target_vocab) for sentence in target_sentences]\n",
        "\n",
        "# Pad sequences to the same length\n",
        "max_input_len = max(len(seq) for seq in input_encoded)\n",
        "max_target_len = max(len(seq) for seq in target_encoded)\n",
        "\n",
        "input_encoded = [seq + [0] * (max_input_len - len(seq)) for seq in input_encoded]\n",
        "target_encoded = [seq + [0] * (max_target_len - len(seq)) for seq in target_encoded]"
      ],
      "metadata": {
        "id": "FtxiYz1WUSVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create <a class=\"autolink\" title=\"Dataset and DataLoader\" href=\"https://course.aiadventures.in/mod/page/view.php?id=2233\">Dataset and DataLoader</a>\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "dataset = TranslationDataset(input_encoded, target_encoded)\n",
        "train_loader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "_9M1duENUSTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Encoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        _, (hidden, cell) = self.lstm(embedded)\n",
        "        return hidden, cell\n",
        "\n",
        "# Define Decoder\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        output = self.fc(output)\n",
        "        return output, hidden, cell"
      ],
      "metadata": {
        "id": "sTC8worrUSQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Seq2Seq Model\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        hidden, cell = self.encoder(src)\n",
        "        outputs = []\n",
        "        input = tgt[:, 0].unsqueeze(1)  # Start with the first word\n",
        "\n",
        "        for t in range(1, tgt.size(1)):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            outputs.append(output)\n",
        "            input = tgt[:, t].unsqueeze(1)  # Teacher forcing\n",
        "\n",
        "        return torch.cat(outputs, dim=1)"
      ],
      "metadata": {
        "id": "7AR3lRWIUSN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "embedding_dim = 10\n",
        "hidden_dim = 20\n",
        "n_epochs = 5\n",
        "\n",
        "# Initialize models\n",
        "encoder = Encoder(input_vocab_size, embedding_dim, hidden_dim)\n",
        "decoder = Decoder(target_vocab_size, embedding_dim, hidden_dim)\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "F_rUS53RQnEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# <a class=\"autolink\" title=\"Training Loop\" href=\"https://course.aiadventures.in/mod/page/view.php?id=2267\">Training Loop</a>\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for src, tgt in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt)\n",
        "        # print(output.view(-1, target_vocab_size))\n",
        "        loss = criterion(output.view(-1, target_vocab_size), tgt[:, 1:].contiguous().view(-1))  # Shift target\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # if (epoch + 1) % 10 == 0:\n",
        "    print(f'Epoch [{epoch + 1}/{n_epochs}], Loss: {total_loss / len(train_loader):.4f}')"
      ],
      "metadata": {
        "id": "JL3U-Fk8QnCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to translate an input sentence\n",
        "def translate(sentence):\n",
        "    model.eval()\n",
        "    encoded_input = encode_sentence(sentence, input_vocab)\n",
        "    input_tensor = torch.tensor(encoded_input + [0] * (max_input_len - len(encoded_input)), dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(input_tensor)\n",
        "        tgt = torch.zeros(1, max_target_len, dtype=torch.long)  # Placeholder for the target\n",
        "        tgt[0, 0] = list(input_vocab.items())[0][1] # start with the first word of target_vocab\n",
        "\n",
        "        for t in range(1, max_target_len):\n",
        "            output, hidden, cell = model.decoder(tgt[:, t-1].unsqueeze(1), hidden, cell)\n",
        "            predicted_idx = output.argmax(2)[:, -1]\n",
        "            tgt[0, t] = predicted_idx\n",
        "            if predicted_idx.item() == 0:  # Stop if we hit padding\n",
        "                break\n",
        "\n",
        "    return ' '.join(target_idx_to_word[idx.item()] for idx in tgt[0] if idx.item() != 0)"
      ],
      "metadata": {
        "id": "qhWgbsfdQnAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "test_sentence = \"see you later\"\n",
        "translated_sentence = translate(test_sentence)\n",
        "print(f'Translation of \"{test_sentence}\": \"{translated_sentence}\"')"
      ],
      "metadata": {
        "id": "IqFlZLGzUu_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RKY__RjaUu8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N5TBBcU4Uu6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NBHQtGmOUu3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1mDKL5JvUu1L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}